# RB-ML-001 - Model Degradation / Accuracy Drop

## Overview

This runbook defines the standardised response procedure for incidents involving degraded model performance, reduced accuracy, or unstable outputs in deployed AI systems.

It supports the objectives of reliability, governance, and user trust.

---

## Purpose

This runbook enables teams to:

- Detect and diagnose model degradation
- Restore stable and reliable performance
- Prevent recurring quality failures
- Maintain audit and accountability records

---

## Applicable Systems

This runbook applies to:

- Production LLM deployments
- Retrieval-Augmented Generation (RAG) systems
- Predictive and classification models
- Decision-support AI services

---

## When to Use

Use this runbook when:

- Monitoring indicates sustained performance decline
- Drift or instability alerts are triggered
- User feedback signals quality degradation
- Output consistency becomes unreliable

---

## Main Runbook Document

Full operational procedures are documented here:

[Model Degradation](https://docs.google.com/document/d/1viih4k2mS5qOHWjjjpAaUzSX39xMzrx4/edit?usp=drive_link&ouid=106343310566021151369&rtpof=true&sd=true) 



---

## Governance Alignment

This runbook aligns with:

- Model governance standards
- Risk management frameworks
- Responsible AI principles
- Continuous evaluation systems

---

## Ownership

Maintained by: AUMI Framework Contributors  
Review Cycle: Periodic governance review
